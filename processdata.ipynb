{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHFp8r2GgDTL",
        "outputId": "00a2810d-7b17-43a6-9746-6fe83de64501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mat73\n",
            "  Downloading mat73-0.59-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mat73) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from mat73) (3.1.0)\n",
            "Installing collected packages: mat73\n",
            "Successfully installed mat73-0.59\n"
          ]
        }
      ],
      "source": [
        "from scipy.fft import fft\n",
        "import scipy\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import set_printoptions\n",
        "from matplotlib import pyplot as plt \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import mannwhitneyu\n",
        "import h5py\n",
        "import math\n",
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install mat73\n",
        "DATASET_DIR = '/content/drive/MyDrive/IMUyAccelerometer/Data'\n",
        "import mat73\n",
        "from scipy.signal import butter,filtfilt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "8d_23VtIBVrX"
      },
      "outputs": [],
      "source": [
        "#CODE UTILITIES\n",
        "\n",
        "#return column of non-pandas matrix\n",
        "def column(matrix, i):\n",
        "    return [row[i] for row in matrix]\n",
        "\n",
        "#Set up Nyquist Frequency and Butterworth lowpass filter to remove noise\n",
        "fs = 100.0 \n",
        "cutoff = 5     \n",
        "nyq = 0.5 * fs  \n",
        "order = 3\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order):\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    # Get the filter coefficients \n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    y = filtfilt(b, a, data, padlen=6)\n",
        "    return y\n",
        "\n",
        "#define a few different feature selection methods to test\n",
        "def featureSelection(features, k, labels, method):\n",
        "    X = features.values\n",
        "    Y = labels\n",
        "    if method == 0:\n",
        "      #RFE\n",
        "      model = LogisticRegression(solver='lbfgs')\n",
        "      rfe = RFE(model, n_features_to_select=k)\n",
        "      fit = rfe.fit(X, Y)\n",
        "    \n",
        "    if method == 1:\n",
        "      #PCA\n",
        "      pca = PCA(n_components=k)\n",
        "      fit = pca.fit(X)\n",
        "\n",
        "    if method == 2:\n",
        "      #Univariate\n",
        "      test = SelectKBest(score_func=f_classif, k=k)\n",
        "      fit = test.fit(X, Y)\n",
        "      set_printoptions(precision=3)\n",
        "      print(fit.scores_)\n",
        "      features = fit.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "uHXMue15CrHJ"
      },
      "outputs": [],
      "source": [
        "#load all LLA data\n",
        "s01 = mat73.loadmat(DATASET_DIR+'/S01.mat')\n",
        "s02 = mat73.loadmat(DATASET_DIR+'/S02.mat')\n",
        "s03 = mat73.loadmat(DATASET_DIR+'/S03.mat')\n",
        "s04 = mat73.loadmat(DATASET_DIR+'/S04.mat')\n",
        "s05 = mat73.loadmat(DATASET_DIR+'/S05.mat')\n",
        "s06 = mat73.loadmat(DATASET_DIR+'/S06.mat')\n",
        "s07 = mat73.loadmat(DATASET_DIR+'/S07.mat')\n",
        "s08 = mat73.loadmat(DATASET_DIR+'/S08.mat')\n",
        "s09 = mat73.loadmat(DATASET_DIR+'/S09.mat')\n",
        "s10 = mat73.loadmat(DATASET_DIR+'/S10.mat')\n",
        "s11 = mat73.loadmat(DATASET_DIR+'/S11.mat')\n",
        "s12 = mat73.loadmat(DATASET_DIR+'/S12.mat')\n",
        "s13 = mat73.loadmat(DATASET_DIR+'/S13.mat')\n",
        "s14 = mat73.loadmat(DATASET_DIR+'/S14.mat')\n",
        "s15 = mat73.loadmat(DATASET_DIR+'/S15.mat')\n",
        "s16 = mat73.loadmat(DATASET_DIR+'/S16.mat')\n",
        "s17 = mat73.loadmat(DATASET_DIR+'/S17.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "c_CEDBWg0U2_"
      },
      "outputs": [],
      "source": [
        "#Load all control data\n",
        "c01 = mat73.loadmat(DATASET_DIR+'/C01.mat')\n",
        "c02 = mat73.loadmat(DATASET_DIR+'/C02.mat')\n",
        "c03 = mat73.loadmat(DATASET_DIR+'/C03.mat')\n",
        "c04 = mat73.loadmat(DATASET_DIR+'/C04.mat')\n",
        "c05 = mat73.loadmat(DATASET_DIR+'/C05.mat')\n",
        "c06 = mat73.loadmat(DATASET_DIR+'/C06.mat')\n",
        "c07 = mat73.loadmat(DATASET_DIR+'/C07.mat')\n",
        "c08 = mat73.loadmat(DATASET_DIR+'/C08.mat')\n",
        "c09 = mat73.loadmat(DATASET_DIR+'/C09.mat')\n",
        "c10 = mat73.loadmat(DATASET_DIR+'/C10.mat')\n",
        "c11 = mat73.loadmat(DATASET_DIR+'/C11.mat')\n",
        "c12 = mat73.loadmat(DATASET_DIR+'/C12.mat')\n",
        "c13 = mat73.loadmat(DATASET_DIR+'/C13.mat')\n",
        "c14 = mat73.loadmat(DATASET_DIR+'/C14.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9DjcAsCaj38",
        "outputId": "4cdc7139-aa19-45f7-887b-eea97480a1ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Accelerometer X', 'Accelerometer Y', 'Accelerometer Z', 'Temperature', 'Gyroscope X', 'Gyroscope Y', 'Gyroscope Z', 'Magnetometer X', 'Magnetometer Y', 'Magnetometer Z']\n",
            "340\n"
          ]
        }
      ],
      "source": [
        "#Isolate the sections of the data we need - See the Instructions.pdf from the original dataset organization\n",
        "#The variable K exists in case of low-RAM runs. The full dataset requires ~64 GB of RAM and >4 hours to perform calculations\n",
        "# to enable the full run, replace k with len(x[i])\n",
        "x = [s01['SubjectData']['IMU']['Bouts']['Data'], s02['SubjectData']['IMU']['Bouts']['Data'], s03['SubjectData']['IMU']['Bouts']['Data'], s04['SubjectData']['IMU']['Bouts']['Data'], s05['SubjectData']['IMU']['Bouts']['Data'], s06['SubjectData']['IMU']['Bouts']['Data'], s07['SubjectData']['IMU']['Bouts']['Data'], s08['SubjectData']['IMU']['Bouts']['Data'], s09['SubjectData']['IMU']['Bouts']['Data'], s10['SubjectData']['IMU']['Bouts']['Data'], s11['SubjectData']['IMU']['Bouts']['Data'], s12['SubjectData']['IMU']['Bouts']['Data'], s13['SubjectData']['IMU']['Bouts']['Data'], s14['SubjectData']['IMU']['Bouts']['Data'], s15['SubjectData']['IMU']['Bouts']['Data'], s16['SubjectData']['IMU']['Bouts']['Data'], s17['SubjectData']['IMU']['Bouts']['Data'] ]\n",
        "\n",
        "y = [s01['SubjectData']['IMU']['Bouts']['Timestamps'], s02['SubjectData']['IMU']['Bouts']['Timestamps'], s03['SubjectData']['IMU']['Bouts']['Timestamps'], s04['SubjectData']['IMU']['Bouts']['Timestamps'], s05['SubjectData']['IMU']['Bouts']['Timestamps'], s06['SubjectData']['IMU']['Bouts']['Timestamps'], s07['SubjectData']['IMU']['Bouts']['Timestamps'], s08['SubjectData']['IMU']['Bouts']['Timestamps'], s09['SubjectData']['IMU']['Bouts']['Timestamps'], s10['SubjectData']['IMU']['Bouts']['Timestamps'], s11['SubjectData']['IMU']['Bouts']['Timestamps'], s12['SubjectData']['IMU']['Bouts']['Timestamps'], s13['SubjectData']['IMU']['Bouts']['Timestamps'], s14['SubjectData']['IMU']['Bouts']['Timestamps'], s15['SubjectData']['IMU']['Bouts']['Timestamps'], s16['SubjectData']['IMU']['Bouts']['Timestamps'], s17['SubjectData']['IMU']['Bouts']['Timestamps'] ]\n",
        "print(s01['SubjectData']['IMU']['Bouts']['DataHeaders'])\n",
        "headers = s01['SubjectData']['IMU']['Bouts']['DataHeaders']\n",
        "data = []\n",
        "time = []\n",
        "k=20\n",
        "for i in range(len(x)): \n",
        "  for j in range(k):\n",
        "    data.append((x[i][j][0]))\n",
        "    time.append(y[i][j][0])\n",
        "  \n",
        "\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuInGfA7fgIu",
        "outputId": "d4fe5d95-cbf5-4133-a0fa-b5ceeeb1aa88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Accelerometer X', 'Accelerometer Y', 'Accelerometer Z', 'Temperature', 'Gyroscope X', 'Gyroscope Y', 'Gyroscope Z', 'Magnetometer X', 'Magnetometer Y', 'Magnetometer Z']\n",
            "336\n"
          ]
        }
      ],
      "source": [
        "x = [c01['SubjectData']['IMU']['Bouts']['Data'], c02['SubjectData']['IMU']['Bouts']['Data'], c03['SubjectData']['IMU']['Bouts']['Data'], c04['SubjectData']['IMU']['Bouts']['Data'], c05['SubjectData']['IMU']['Bouts']['Data'], c06['SubjectData']['IMU']['Bouts']['Data'], c07['SubjectData']['IMU']['Bouts']['Data'], c08['SubjectData']['IMU']['Bouts']['Data'], c09['SubjectData']['IMU']['Bouts']['Data'], c10['SubjectData']['IMU']['Bouts']['Data'], c11['SubjectData']['IMU']['Bouts']['Data'], c12['SubjectData']['IMU']['Bouts']['Data'], c13['SubjectData']['IMU']['Bouts']['Data'], c14['SubjectData']['IMU']['Bouts']['Data'] ]\n",
        "y = [c01['SubjectData']['IMU']['Bouts']['Timestamps'], c02['SubjectData']['IMU']['Bouts']['Timestamps'], c03['SubjectData']['IMU']['Bouts']['Timestamps'], c04['SubjectData']['IMU']['Bouts']['Timestamps'], c05['SubjectData']['IMU']['Bouts']['Timestamps'], c06['SubjectData']['IMU']['Bouts']['Timestamps'], c07['SubjectData']['IMU']['Bouts']['Timestamps'], c08['SubjectData']['IMU']['Bouts']['Timestamps'], c09['SubjectData']['IMU']['Bouts']['Timestamps'], c10['SubjectData']['IMU']['Bouts']['Timestamps'], c11['SubjectData']['IMU']['Bouts']['Timestamps'], c12['SubjectData']['IMU']['Bouts']['Timestamps'], c13['SubjectData']['IMU']['Bouts']['Timestamps'], c14['SubjectData']['IMU']['Bouts']['Timestamps'] ]\n",
        "print(c01['SubjectData']['IMU']['Bouts']['DataHeaders'])\n",
        "headers = c01['SubjectData']['IMU']['Bouts']['DataHeaders']\n",
        "data = []\n",
        "time = []\n",
        "k=24\n",
        "for i in range(len(x)): \n",
        "  for j in range(k):\n",
        "    data.append((x[i][j][0]))\n",
        "    time.append(y[i][j][0])\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvnuzApUoUV2",
        "outputId": "652804f2-6387-444a-c5cc-a5804328585c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333\n",
            "333\n"
          ]
        }
      ],
      "source": [
        "#clean up our data, remove incomplete data sets and drop unnessecary columns\n",
        "# then, apply the butterworth filter to Accelerometer data\n",
        "#We also send our cleaned up data to a pandas DataFrame for easier manipulation\n",
        "\n",
        "datax = []\n",
        "j = -1\n",
        "for i in range(len(data)):\n",
        "  #cull all incomplete data / non waveform data\n",
        "  if type(data[i][0]) is np.float64 or len(data[i][0])<10 or \\\n",
        "   sum(data[i][0])==0:\n",
        "    continue\n",
        "  datax.append(pd.DataFrame(data[i]))\n",
        "  datax[j].columns = headers\n",
        "  datax[j]['Time'] = time[i]\n",
        "print(len(datax))\n",
        "# butterworth filter on all Accelerometer data, drop unneccesary temp data\n",
        "for k in range(len(datax)):\n",
        "  x = butter_lowpass_filter(datax[k].iloc[:,0], cutoff, fs, order)\n",
        "  datax[k].iloc[:,0] = x\n",
        "  y = butter_lowpass_filter(datax[k].iloc[:,1], cutoff, fs, order)\n",
        "  datax[k].iloc[:,0] = y\n",
        "  z = butter_lowpass_filter(datax[k].iloc[:,2], cutoff, fs, order)\n",
        "  datax[k].iloc[:,0] = z\n",
        "  datax[k].drop(datax[k].columns[[3]], axis=1, inplace=True)\n",
        "\n",
        "datac = []\n",
        "j = -1\n",
        "for i in range(len(data)):\n",
        "  #cull all incomplete data / non waveform data\n",
        "  if type(data[i][0]) is np.float64 or len(data[i][0])<10 or \\\n",
        "   sum(data[i][0])==0:\n",
        "    continue\n",
        "  datac.append(pd.DataFrame(data[i]))\n",
        "  datac[j].columns = headers\n",
        "  datac[j]['Time'] = time[i]\n",
        "print(len(datac))\n",
        "# butterworth filter on all Accelerometer data, drop unneccesary temp data\n",
        "for k in range(len(datac)):\n",
        "  x = butter_lowpass_filter(datac[k].iloc[:,0], cutoff, fs, order)\n",
        "  datac[k].iloc[:,0] = x\n",
        "  y = butter_lowpass_filter(datac[k].iloc[:,1], cutoff, fs, order)\n",
        "  datac[k].iloc[:,0] = y\n",
        "  z = butter_lowpass_filter(datac[k].iloc[:,2], cutoff, fs, order)\n",
        "  datac[k].iloc[:,0] = z\n",
        "  datac[k].drop(datac[k].columns[[3]], axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOe1BsJMwnVa",
        "outputId": "aac5ef0a-f942-4584-fc6c-6fb66fdea75c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-194321ca3392>:10: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  jerkx.append((datax[k].iloc[:,0][i]-datax[k].iloc[:,0][i+1])/(datax[k].loc[:,'Time'][i]-datax[k].loc[:,'Time'][i+1]))\n",
            "<ipython-input-50-194321ca3392>:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  jerky.append((datax[k].iloc[:,1][i]-datax[k].iloc[:,1][i+1])/(datax[k].loc[:,'Time'][i]-datax[k].loc[:,'Time'][i+1]))\n",
            "<ipython-input-50-194321ca3392>:12: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  jerkz.append((datax[k].iloc[:,2][i]-datax[k].iloc[:,2][i+1])/(datax[k].loc[:,'Time'][i]-datax[k].loc[:,'Time'][i+1]))\n",
            "<ipython-input-50-194321ca3392>:12: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  jerkz.append((datax[k].iloc[:,2][i]-datax[k].iloc[:,2][i+1])/(datax[k].loc[:,'Time'][i]-datax[k].loc[:,'Time'][i+1]))\n",
            "<ipython-input-50-194321ca3392>:11: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  jerky.append((datax[k].iloc[:,1][i]-datax[k].iloc[:,1][i+1])/(datax[k].loc[:,'Time'][i]-datax[k].loc[:,'Time'][i+1]))\n"
          ]
        }
      ],
      "source": [
        "#calculate jerk from acceleration data\n",
        "# Jerk - the third derivative of position, or first derivative of Acceleration, describes \n",
        "# change in Acceleration over time. This part of the process takes the longest of all calculations.\n",
        "for k in range(len(datax)):\n",
        "  jerkx = []\n",
        "  jerky = []\n",
        "  jerkz = []\n",
        "  jerkx.append(0)\n",
        "  jerky.append(0)\n",
        "  jerkz.append(0)\n",
        "  for i in range(len(datax[k].iloc[:,1])-1):\n",
        "    jerkx.append((datax[k].iloc[:,0][i]-datax[k].iloc[:,0][i+1])/(datax[k].loc[:,'Time'][i]-datax[k].loc[:,'Time'][i+1]))\n",
        "    jerky.append((datax[k].iloc[:,1][i]-datax[k].iloc[:,1][i+1])/(datax[k].loc[:,'Time'][i]-datax[k].loc[:,'Time'][i+1]))\n",
        "    jerkz.append((datax[k].iloc[:,2][i]-datax[k].iloc[:,2][i+1])/(datax[k].loc[:,'Time'][i]-datax[k].loc[:,'Time'][i+1]))\n",
        "  datax[k]['Jerk X'] = jerkx\n",
        "  datax[k]['Jerk Y'] = jerky\n",
        "  datax[k]['Jerk Z'] = jerkz "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate jerk on control dataset\n",
        "for k in range(len(datac)):\n",
        "  jerkx = []\n",
        "  jerky = []\n",
        "  jerkz = []\n",
        "  jerkx.append(0)\n",
        "  jerky.append(0)\n",
        "  jerkz.append(0)\n",
        "  for i in range(len(datac[k].iloc[:,1])-1):\n",
        "    jerkx.append((datac[k].iloc[:,0][i]-datac[k].iloc[:,0][i+1])/(datac[k].loc[:,'Time'][i]-datac[k].loc[:,'Time'][i+1]))\n",
        "    jerky.append((datac[k].iloc[:,1][i]-datac[k].iloc[:,1][i+1])/(datac[k].loc[:,'Time'][i]-datac[k].loc[:,'Time'][i+1]))\n",
        "    jerkz.append((datac[k].iloc[:,2][i]-datac[k].iloc[:,2][i+1])/(datac[k].loc[:,'Time'][i]-datac[k].loc[:,'Time'][i+1]))\n",
        "  datac[k]['Jerk X'] = jerkx\n",
        "  datac[k]['Jerk Y'] = jerky\n",
        "  datac[k]['Jerk Z'] = jerkz "
      ],
      "metadata": {
        "id": "g9Pv0OdeE6Ji"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Accelerometer and Jerk Magnitudes on Full Dataset\n",
        "# Magnitude of a vector = sqrt(x^2+y^2+z^2)\n",
        "#This is likely the 2nd longest operation in the whole thing\n",
        "for k in range(len(datac)):\n",
        "  accelmag = []\n",
        "  jerkmag = []\n",
        "  for i in range(len(datac[k].iloc[:,1])):\n",
        "    accelmag.append( math.sqrt(datac[k].iloc[:,0][i]**2 + datac[k].iloc[:,1][i]**2 + datac[k].iloc[:,2][i]**2) )\n",
        "    jerkmag.append( math.sqrt(datac[k].iloc[:,10][i]**2 + datac[k].iloc[:,11][i]**2 + datac[k].iloc[:,12][i]**2) )\n",
        "  datac[k]['Accel Mag'] = accelmag\n",
        "  datac[k]['Jerk Mag'] = jerkmag\n",
        "\n",
        "for k in range(len(datax)):\n",
        "  accelmag = []\n",
        "  jerkmag = []\n",
        "  for i in range(len(datax[k].iloc[:,1])):\n",
        "    accelmag.append( math.sqrt(datax[k].iloc[:,0][i]**2 + datax[k].iloc[:,1][i]**2 + datax[k].iloc[:,2][i]**2) )\n",
        "    jerkmag.append( math.sqrt(datax[k].iloc[:,10][i]**2 + datax[k].iloc[:,11][i]**2 + datax[k].iloc[:,12][i]**2) )\n",
        "  datax[k]['Accel Mag'] = accelmag\n",
        "  datax[k]['Jerk Mag'] = jerkmag\n"
      ],
      "metadata": {
        "id": "tuArbWbqcEdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUgFA5mdFz7w"
      },
      "outputs": [],
      "source": [
        "# OPTIONALLY, SAVE DATA TO CSVs TO RE-IMPORT FOR LATER EVALUATION\n",
        "for k in range(len(datac)):\n",
        "  filename = Path(DATASET_DIR+'/control/'+str(k)+'.csv')\n",
        "  datac[k].to_csv(filename)\n",
        "\n",
        "for k in range(len(datax)):\n",
        "  filename = Path(DATASET_DIR+'/lla/'+str(k)+'.csv')\n",
        "  datax[k].to_csv(filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONALLY, IMPORT DATA BACK FROM CSVs TO SAVE TIME/RAM on future runs\n",
        "k = 0\n",
        "datax = []\n",
        "filenameL = Path(DATASET_DIR+'/lla/'+str(k)+'.csv')\n",
        "for k in range(169):\n",
        "  df = pd.read_csv(filenameL)\n",
        "  datax.append(df)\n",
        "\n",
        "k = 0\n",
        "datac = []\n",
        "filenameC = Path(DATASET_DIR+'/control/'+str(k)+'.csv')\n",
        "for k in range(236):\n",
        "  df = pd.read_csv(filenameC)\n",
        "  datac.append(df)\n"
      ],
      "metadata": {
        "id": "U5GJfVq4bAYE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate Sliding Windows. Divy up the data into sliding windows of size 100 (1s of data) + a 33 frame offset\n",
        "print(len(datax))\n",
        "temp = datax\n",
        "datax = []\n",
        "for k in range(len(temp)):\n",
        "  c = 1\n",
        "  while len(temp[k]) - c >=100:\n",
        "    datax.append(temp.iloc[c,c+100])\n",
        "    c+=33\n",
        "print(len(datax))\n",
        "print(len(datac))\n",
        "temp = datac\n",
        "datac = []\n",
        "for k in range(len(temp)):\n",
        "  c = 1\n",
        "  while len(temp[k]) - c >=100:\n",
        "    datac.append(temp.iloc[c,c+100])\n",
        "    c+=33\n",
        "print(len(datac))"
      ],
      "metadata": {
        "id": "LOzuR6Gh4kWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get wavelet/fft features. These are complex numbers so we will need to use the magnitude \n",
        "# instead of the raw fft values in order to perform evaluations on them\n",
        "fft = []\n",
        "\n",
        "#fft on LLA dataset\n",
        "for k in range(len(datax)):\n",
        "  df = pd.DataFrame()\n",
        "  df['accXfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Accelerometer X']))]\n",
        "  df['accYfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Accelerometer Y']))]\n",
        "  df['accZfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Accelerometer Z']))]\n",
        "  df['gyroXfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Gyroscope X']))]\n",
        "  df['gyroYfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Gyroscope Y']))]\n",
        "  df['gyroZfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Gyroscope Z']))]\n",
        "  df['magXfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Magnetometer X']))]\n",
        "  df['magYfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Magnetometer Y']))]\n",
        "  df['magZfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Magnetometer Z']))]\n",
        "  df['jerkXfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Jerk X']))]\n",
        "  df['jerkYfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Jerk Y']))]\n",
        "  df['jerkZfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Jerk Z']))]\n",
        "  df['magAccelfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Accel Mag']))]\n",
        "  df['magJerkfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Jerk Mag']))]\n",
        "  fft.append(df)\n",
        "for k in range(len(datac)):\n",
        "  df = pd.DataFrame()\n",
        "  df['accXfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Accelerometer X']))]\n",
        "  df['accYfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Accelerometer Y']))]\n",
        "  df['accZfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Accelerometer Z']))]\n",
        "  df['gyroXfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Gyroscope X']))]\n",
        "  df['gyroYfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Gyroscope Y']))]\n",
        "  df['gyroZfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Gyroscope Z']))]\n",
        "  df['magXfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Magnetometer X']))]\n",
        "  df['magYfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Magnetometer Y']))]\n",
        "  df['magZfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Magnetometer Z']))]\n",
        "  df['jerkXfft'] = [abs(ele) for ele in fft(np.array(datax[k].loc[:,'Jerk X']))]\n",
        "  df['jerkYfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Jerk Y']))]\n",
        "  df['jerkZfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Jerk Z']))]\n",
        "  df['magAccelfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Accel Mag']))]\n",
        "  df['magJerkfft'] = [abs(ele) for ele in fft(np.array(datac[k].loc[:,'Jerk Mag']))]\n",
        "  fft.append(df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "Y7sjbdcFIYaO",
        "outputId": "64f03863-3b68-4988-f1f6-532208e435bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9b921167fda7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Accelerometer X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accXfft'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accYfft'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Accelerometer Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accZfft'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Accelerometer Z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gyroXfft'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Gyroscope X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/fft/_backend.py\u001b[0m in \u001b[0;36m__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/fft/_pocketfft/basic.py\u001b[0m in \u001b[0;36mc2c\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     15\u001b[0m         raise NotImplementedError('Passing a precomputed plan is not yet '\n\u001b[1;32m     16\u001b[0m                                   'supported by scipy.fft functions')\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asfarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0moverwrite_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverwrite_x\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_datacopied\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/fft/_pocketfft/helper.py\u001b[0m in \u001b[0;36m_asfarray\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewbyteorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Always align input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ALIGNED'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/flags.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'ALIGNED'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get features from the time domain. This is also where we apply our labels to each waveform \n",
        "features = []\n",
        "for k in range(len(datax)):\n",
        "  item = [0, min(datax[k].loc[:,'Accelerometer X']), max(datax[k].loc[:,'Accelerometer X']), np.mean(datax[k].loc[:,'Accelerometer X']), np.std(datax[k].loc[:,'Accelerometer X'], axis=0),\n",
        "          min(datax[k].loc[:,'Accelerometer Y']), max(datax[k].loc[:,'Accelerometer Y']), np.mean(datax[k].loc[:,'Accelerometer Y']), np.std(datax[k].loc[:,'Accelerometer Y'], axis=0),\n",
        "          min(datax[k].loc[:,'Accelerometer Z']), max(datax[k].loc[:,'Accelerometer Z']), np.mean(datax[k].loc[:,'Accelerometer Z']), np.std(datax[k].loc[:,'Accelerometer Z'], axis=0),\n",
        "          min(datax[k].loc[:,'Gyroscope X']), max(datax[k].loc[:,'Gyroscope X']), np.mean(datax[k].loc[:,'Gyroscope X']), np.std(datax[k].loc[:,'Gyroscope X'], axis=0),\n",
        "          min(datax[k].loc[:,'Gyroscope Y']), max(datax[k].loc[:,'Gyroscope Y']), np.mean(datax[k].loc[:,'Gyroscope Y']), np.std(datax[k].loc[:,'Gyroscope Y'], axis=0),\n",
        "          min(datax[k].loc[:,'Gyroscope Z']), max(datax[k].loc[:,'Gyroscope Z']), np.mean(datax[k].loc[:,'Gyroscope Z']), np.std(datax[k].loc[:,'Gyroscope Z'], axis=0),\n",
        "          min(datax[k].loc[:,'Magnetometer X']), max(datax[k].loc[:,'Magnetometer X']), np.mean(datax[k].loc[:,'Magnetometer X']), np.std(datax[k].loc[:,'Magnetometer X'], axis=0),\n",
        "          min(datax[k].loc[:,'Magnetometer Y']), max(datax[k].loc[:,'Magnetometer Y']), np.mean(datax[k].loc[:,'Magnetometer Y']), np.std(datax[k].loc[:,'Magnetometer Y'], axis=0),\n",
        "          min(datax[k].loc[:,'Magnetometer Z']), max(datax[k].loc[:,'Magnetometer Z']), np.mean(datax[k].loc[:,'Magnetometer Z']), np.std(datax[k].loc[:,'Magnetometer Z'], axis=0),\n",
        "          min(datax[k].loc[:,'Jerk X']), max(datax[k].loc[:,'Jerk X']), np.mean(datax[k].loc[:,'Jerk X']), np.std(datax[k].loc[:,'Jerk X'], axis=0),\n",
        "          min(datax[k].loc[:,'Jerk Y']), max(datax[k].loc[:,'Jerk Y']), np.mean(datax[k].loc[:,'Jerk Y']), np.std(datax[k].loc[:,'Jerk Y'], axis=0),\n",
        "          min(datax[k].loc[:,'Jerk Z']), max(datax[k].loc[:,'Jerk Z']), np.mean(datax[k].loc[:,'Jerk Z']), np.std(datax[k].loc[:,'Jerk Z'], axis=0),\n",
        "          min(datax[k].loc[:,'Accel Mag']), max(datax[k].loc[:,'Accel Mag']), np.mean(datax[k].loc[:,'Accel Mag']), np.std(datax[k].loc[:,'Accel Mag'], axis=0),\n",
        "          min(datax[k].loc[:,'Jerk Mag']), max(datax[k].loc[:,'Jerk Mag']), np.mean(datax[k].loc[:,'Jerk Mag']), np.std(datax[k].loc[:,'Jerk Mag'], axis=0),]\n",
        "  features.append(item)\n",
        "for k in range(len(datac)):\n",
        "  item = [1, min(datac[k].loc[:,'Accelerometer X']), max(datac[k].loc[:,'Accelerometer X']), np.mean(datac[k].loc[:,'Accelerometer X']), np.std(datac[k].loc[:,'Accelerometer X'], axis=0),\n",
        "          min(datac[k].loc[:,'Accelerometer Y']), max(datac[k].loc[:,'Accelerometer Y']), np.mean(datac[k].loc[:,'Accelerometer Y']), np.std(datac[k].loc[:,'Accelerometer Y'], axis=0),\n",
        "          min(datac[k].loc[:,'Accelerometer Z']), max(datac[k].loc[:,'Accelerometer Z']), np.mean(datac[k].loc[:,'Accelerometer Z']), np.std(datac[k].loc[:,'Accelerometer Z'], axis=0),\n",
        "          min(datac[k].loc[:,'Gyroscope X']), max(datac[k].loc[:,'Gyroscope X']), np.mean(datac[k].loc[:,'Gyroscope X']), np.std(datac[k].loc[:,'Gyroscope X'], axis=0),\n",
        "          min(datac[k].loc[:,'Gyroscope Y']), max(datac[k].loc[:,'Gyroscope Y']), np.mean(datac[k].loc[:,'Gyroscope Y']), np.std(datac[k].loc[:,'Gyroscope Y'], axis=0),\n",
        "          min(datac[k].loc[:,'Gyroscope Z']), max(datac[k].loc[:,'Gyroscope Z']), np.mean(datac[k].loc[:,'Gyroscope Z']), np.std(datac[k].loc[:,'Gyroscope Z'], axis=0),\n",
        "          min(datac[k].loc[:,'Magnetometer X']), max(datac[k].loc[:,'Magnetometer X']), np.mean(datac[k].loc[:,'Magnetometer X']), np.std(datac[k].loc[:,'Magnetometer X'], axis=0),\n",
        "          min(datac[k].loc[:,'Magnetometer Y']), max(datac[k].loc[:,'Magnetometer Y']), np.mean(datac[k].loc[:,'Magnetometer Y']), np.std(datac[k].loc[:,'Magnetometer Y'], axis=0),\n",
        "          min(datac[k].loc[:,'Magnetometer Z']), max(datac[k].loc[:,'Magnetometer Z']), np.mean(datac[k].loc[:,'Magnetometer Z']), np.std(datac[k].loc[:,'Magnetometer Z'], axis=0),\n",
        "          min(datac[k].loc[:,'Jerk X']), max(datac[k].loc[:,'Jerk X']), np.mean(datac[k].loc[:,'Jerk X']), np.std(datac[k].loc[:,'Jerk X'], axis=0),\n",
        "          min(datac[k].loc[:,'Jerk Y']), max(datac[k].loc[:,'Jerk Y']), np.mean(datac[k].loc[:,'Jerk Y']), np.std(datac[k].loc[:,'Jerk Y'], axis=0),\n",
        "          min(datac[k].loc[:,'Jerk Z']), max(datac[k].loc[:,'Jerk Z']), np.mean(datac[k].loc[:,'Jerk Z']), np.std(datac[k].loc[:,'Jerk Z'], axis=0),\n",
        "          min(datac[k].loc[:,'Accel Mag']), max(datac[k].loc[:,'Accel Mag']), np.mean(datac[k].loc[:,'Accel Mag']), np.std(datac[k].loc[:,'Accel Mag'], axis=0),\n",
        "          min(datac[k].loc[:,'Jerk Mag']), max(datac[k].loc[:,'Jerk Mag']), np.mean(datac[k].loc[:,'Jerk Mag']), np.std(datac[k].loc[:,'Jerk Mag'], axis=0),]\n",
        "  features.append(item)\n"
      ],
      "metadata": {
        "id": "VdGfZ0RscEXy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate and append fft features \n",
        "features = []\n",
        "for k in range(len(datax)):\n",
        "  item = [0, min(datax[k].loc[:,'Accelerometer X']), max(datax[k].loc[:,'Accelerometer X']), np.mean(datax[k].loc[:,'Accelerometer X']), np.std(datax[k].loc[:,'Accelerometer X'], axis=0),\n",
        "          min(datax[k].loc[:,'Accelerometer Y']), max(datax[k].loc[:,'Accelerometer Y']), np.mean(datax[k].loc[:,'Accelerometer Y']), np.std(datax[k].loc[:,'Accelerometer Y'], axis=0),\n",
        "          min(datax[k].loc[:,'Accelerometer Z']), max(datax[k].loc[:,'Accelerometer Z']), np.mean(datax[k].loc[:,'Accelerometer Z']), np.std(datax[k].loc[:,'Accelerometer Z'], axis=0),\n",
        "          min(datax[k].loc[:,'Gyroscope X']), max(datax[k].loc[:,'Gyroscope X']), np.mean(datax[k].loc[:,'Gyroscope X']), np.std(datax[k].loc[:,'Gyroscope X'], axis=0),\n",
        "          min(datax[k].loc[:,'Gyroscope Y']), max(datax[k].loc[:,'Gyroscope Y']), np.mean(datax[k].loc[:,'Gyroscope Y']), np.std(datax[k].loc[:,'Gyroscope Y'], axis=0),\n",
        "          min(datax[k].loc[:,'Gyroscope Z']), max(datax[k].loc[:,'Gyroscope Z']), np.mean(datax[k].loc[:,'Gyroscope Z']), np.std(datax[k].loc[:,'Gyroscope Z'], axis=0),\n",
        "          min(datax[k].loc[:,'Magnetometer X']), max(datax[k].loc[:,'Magnetometer X']), np.mean(datax[k].loc[:,'Magnetometer X']), np.std(datax[k].loc[:,'Magnetometer X'], axis=0),\n",
        "          min(datax[k].loc[:,'Magnetometer Y']), max(datax[k].loc[:,'Magnetometer Y']), np.mean(datax[k].loc[:,'Magnetometer Y']), np.std(datax[k].loc[:,'Magnetometer Y'], axis=0),\n",
        "          min(datax[k].loc[:,'Magnetometer Z']), max(datax[k].loc[:,'Magnetometer Z']), np.mean(datax[k].loc[:,'Magnetometer Z']), np.std(datax[k].loc[:,'Magnetometer Z'], axis=0),\n",
        "          min(datax[k].loc[:,'Jerk X']), max(datax[k].loc[:,'Jerk X']), np.mean(datax[k].loc[:,'Jerk X']), np.std(datax[k].loc[:,'Jerk X'], axis=0),\n",
        "          min(datax[k].loc[:,'Jerk Y']), max(datax[k].loc[:,'Jerk Y']), np.mean(datax[k].loc[:,'Jerk Y']), np.std(datax[k].loc[:,'Jerk Y'], axis=0),\n",
        "          min(datax[k].loc[:,'Jerk Z']), max(datax[k].loc[:,'Jerk Z']), np.mean(datax[k].loc[:,'Jerk Z']), np.std(datax[k].loc[:,'Jerk Z'], axis=0),\n",
        "          min(datax[k].loc[:,'Accel Mag']), max(datax[k].loc[:,'Accel Mag']), np.mean(datax[k].loc[:,'Accel Mag']), np.std(datax[k].loc[:,'Accel Mag'], axis=0),\n",
        "          min(datax[k].loc[:,'Jerk Mag']), max(datax[k].loc[:,'Jerk Mag']), np.mean(datax[k].loc[:,'Jerk Mag']), np.std(datax[k].loc[:,'Jerk Mag'], axis=0),]\n",
        "  features.append(item)\n",
        "for k in range(len(datac)):\n",
        "  item = [1, min(datac[k].loc[:,'Accelerometer X']), max(datac[k].loc[:,'Accelerometer X']), np.mean(datac[k].loc[:,'Accelerometer X']), np.std(datac[k].loc[:,'Accelerometer X'], axis=0),\n",
        "          min(datac[k].loc[:,'Accelerometer Y']), max(datac[k].loc[:,'Accelerometer Y']), np.mean(datac[k].loc[:,'Accelerometer Y']), np.std(datac[k].loc[:,'Accelerometer Y'], axis=0),\n",
        "          min(datac[k].loc[:,'Accelerometer Z']), max(datac[k].loc[:,'Accelerometer Z']), np.mean(datac[k].loc[:,'Accelerometer Z']), np.std(datac[k].loc[:,'Accelerometer Z'], axis=0),\n",
        "          min(datac[k].loc[:,'Gyroscope X']), max(datac[k].loc[:,'Gyroscope X']), np.mean(datac[k].loc[:,'Gyroscope X']), np.std(datac[k].loc[:,'Gyroscope X'], axis=0),\n",
        "          min(datac[k].loc[:,'Gyroscope Y']), max(datac[k].loc[:,'Gyroscope Y']), np.mean(datac[k].loc[:,'Gyroscope Y']), np.std(datac[k].loc[:,'Gyroscope Y'], axis=0),\n",
        "          min(datac[k].loc[:,'Gyroscope Z']), max(datac[k].loc[:,'Gyroscope Z']), np.mean(datac[k].loc[:,'Gyroscope Z']), np.std(datac[k].loc[:,'Gyroscope Z'], axis=0),\n",
        "          min(datac[k].loc[:,'Magnetometer X']), max(datac[k].loc[:,'Magnetometer X']), np.mean(datac[k].loc[:,'Magnetometer X']), np.std(datac[k].loc[:,'Magnetometer X'], axis=0),\n",
        "          min(datac[k].loc[:,'Magnetometer Y']), max(datac[k].loc[:,'Magnetometer Y']), np.mean(datac[k].loc[:,'Magnetometer Y']), np.std(datac[k].loc[:,'Magnetometer Y'], axis=0),\n",
        "          min(datac[k].loc[:,'Magnetometer Z']), max(datac[k].loc[:,'Magnetometer Z']), np.mean(datac[k].loc[:,'Magnetometer Z']), np.std(datac[k].loc[:,'Magnetometer Z'], axis=0),\n",
        "          min(datac[k].loc[:,'Jerk X']), max(datac[k].loc[:,'Jerk X']), np.mean(datac[k].loc[:,'Jerk X']), np.std(datac[k].loc[:,'Jerk X'], axis=0),\n",
        "          min(datac[k].loc[:,'Jerk Y']), max(datac[k].loc[:,'Jerk Y']), np.mean(datac[k].loc[:,'Jerk Y']), np.std(datac[k].loc[:,'Jerk Y'], axis=0),\n",
        "          min(datac[k].loc[:,'Jerk Z']), max(datac[k].loc[:,'Jerk Z']), np.mean(datac[k].loc[:,'Jerk Z']), np.std(datac[k].loc[:,'Jerk Z'], axis=0),\n",
        "          min(datac[k].loc[:,'Accel Mag']), max(datac[k].loc[:,'Accel Mag']), np.mean(datac[k].loc[:,'Accel Mag']), np.std(datac[k].loc[:,'Accel Mag'], axis=0),\n",
        "          min(datac[k].loc[:,'Jerk Mag']), max(datac[k].loc[:,'Jerk Mag']), np.mean(datac[k].loc[:,'Jerk Mag']), np.std(datac[k].loc[:,'Jerk Mag'], axis=0),]\n",
        "  features.append(item)\n"
      ],
      "metadata": {
        "id": "WcqntHR-ewLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "df = pd.DataFrame(features)\n",
        "x = df.sample(frac=1)\n",
        "y = x.iloc[:,0]\n",
        "x = x.drop(labels=0, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qUUCLGqFKaZ",
        "outputId": "b683f7d8-dae9-4efe-ed9d-8588f67032a4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           1         2         3         4         5         6         7   \\\n",
            "139 -0.806563  1.634289  0.608125  0.177891 -4.783203  1.035010 -0.753776   \n",
            "116 -0.806563  1.634289  0.608125  0.177891 -4.783203  1.035010 -0.753776   \n",
            "106 -0.806563  1.634289  0.608125  0.177891 -4.783203  1.035010 -0.753776   \n",
            "221 -1.597056  2.395973  0.815542  0.275326 -9.824219  2.314941 -0.558163   \n",
            "366 -1.597056  2.395973  0.815542  0.275326 -9.824219  2.314941 -0.558163   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "289 -1.597056  2.395973  0.815542  0.275326 -9.824219  2.314941 -0.558163   \n",
            "206 -1.597056  2.395973  0.815542  0.275326 -9.824219  2.314941 -0.558163   \n",
            "109 -0.806563  1.634289  0.608125  0.177891 -4.783203  1.035010 -0.753776   \n",
            "325 -1.597056  2.395973  0.815542  0.275326 -9.824219  2.314941 -0.558163   \n",
            "84  -0.806563  1.634289  0.608125  0.177891 -4.783203  1.035010 -0.753776   \n",
            "\n",
            "           8         9         10  ...           47            48        49  \\\n",
            "139  0.247115 -3.281738  5.230469  ...   718.755942  1.425154e+08  0.375636   \n",
            "116  0.247115 -3.281738  5.230469  ...   718.755942  1.425154e+08  0.375636   \n",
            "106  0.247115 -3.281738  5.230469  ...   718.755942  1.425154e+08  0.375636   \n",
            "221  0.572116 -4.982910  6.950195  ... -3641.844614  6.252380e+08  0.278629   \n",
            "366  0.572116 -4.982910  6.950195  ... -3641.844614  6.252380e+08  0.278629   \n",
            "..        ...       ...       ...  ...          ...           ...       ...   \n",
            "289  0.572116 -4.982910  6.950195  ... -3641.844614  6.252380e+08  0.278629   \n",
            "206  0.572116 -4.982910  6.950195  ... -3641.844614  6.252380e+08  0.278629   \n",
            "109  0.247115 -3.281738  5.230469  ...   718.755942  1.425154e+08  0.375636   \n",
            "325  0.572116 -4.982910  6.950195  ... -3641.844614  6.252380e+08  0.278629   \n",
            "84   0.247115 -3.281738  5.230469  ...   718.755942  1.425154e+08  0.375636   \n",
            "\n",
            "            50        51        52   53            54            55  \\\n",
            "139   5.890012  1.180965  0.274069  0.0  4.685942e+09  3.371452e+07   \n",
            "116   5.890012  1.180965  0.274069  0.0  4.685942e+09  3.371452e+07   \n",
            "106   5.890012  1.180965  0.274069  0.0  4.685942e+09  3.371452e+07   \n",
            "221  11.010060  1.409096  0.543146  0.0  1.135584e+10  1.564965e+08   \n",
            "366  11.010060  1.409096  0.543146  0.0  1.135584e+10  1.564965e+08   \n",
            "..         ...       ...       ...  ...           ...           ...   \n",
            "289  11.010060  1.409096  0.543146  0.0  1.135584e+10  1.564965e+08   \n",
            "206  11.010060  1.409096  0.543146  0.0  1.135584e+10  1.564965e+08   \n",
            "109   5.890012  1.180965  0.274069  0.0  4.685942e+09  3.371452e+07   \n",
            "325  11.010060  1.409096  0.543146  0.0  1.135584e+10  1.564965e+08   \n",
            "84    5.890012  1.180965  0.274069  0.0  4.685942e+09  3.371452e+07   \n",
            "\n",
            "               56  \n",
            "139  1.384930e+08  \n",
            "116  1.384930e+08  \n",
            "106  1.384930e+08  \n",
            "221  6.053546e+08  \n",
            "366  6.053546e+08  \n",
            "..            ...  \n",
            "289  6.053546e+08  \n",
            "206  6.053546e+08  \n",
            "109  1.384930e+08  \n",
            "325  6.053546e+08  \n",
            "84   1.384930e+08  \n",
            "\n",
            "[405 rows x 56 columns]\n",
            "405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Random Forest Classifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
        "\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred=clf.predict(X_test)\n",
        "yval_pred=clf.predict(X_val)\n",
        "from sklearn import metrics\n",
        "# Model Accuracy\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_val, yval_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-8eqORtbkqN",
        "outputId": "cf981471-690f-4cba-a786-8dcf0c872aba"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5327868852459017\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "history_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}